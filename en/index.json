[{"body":"","link":"https://dennys.github.io/en/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://dennys.github.io/en/","section":"","tags":null,"title":"Dennys Diary"},{"body":"","link":"https://dennys.github.io/en/doc/","section":"doc","tags":null,"title":"Docs"},{"body":"","link":"https://dennys.github.io/en/categories/it/","section":"categories","tags":null,"title":"IT"},{"body":"","link":"https://dennys.github.io/en/tags/javascript/","section":"tags","tags":null,"title":"JavaScript"},{"body":"","link":"https://dennys.github.io/en/tags/node/","section":"tags","tags":null,"title":"Node"},{"body":"","link":"https://dennys.github.io/en/series/node/","section":"series","tags":null,"title":"Node"},{"body":"Requirement I aim to develop a [Node].js(https://nodejs.org/)-based FastAPI that is OpenAPI compatible (formerly known as Swagger). To accomplish this, I will employ RepiDoc for generating OpenAPI documents and keep track of the API's execution status using swagger-stats.\nCode This is package.json\n1{ 2 \u0026#34;name\u0026#34;: \u0026#34;fastify-example\u0026#34;, 3 \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, 4 \u0026#34;description\u0026#34;: \u0026#34;A simple Fastify example with OpenAPI\u0026#34;, 5 \u0026#34;type\u0026#34;: \u0026#34;commonjs\u0026#34;, 6 \u0026#34;scripts\u0026#34;: { 7 \u0026#34;start\u0026#34;: \u0026#34;node app.js\u0026#34; 8 }, 9 \u0026#34;dependencies\u0026#34;: { 10 \u0026#34;@fastify/express\u0026#34;: \u0026#34;^2.3.0\u0026#34;, 11 \u0026#34;@fastify/static\u0026#34;: \u0026#34;^6.11.2\u0026#34;, 12 \u0026#34;@fastify/swagger\u0026#34;: \u0026#34;^8.10.1\u0026#34;, 13 \u0026#34;@fastify/swagger-ui\u0026#34;: \u0026#34;^1.9.3\u0026#34;, 14 \u0026#34;fastify\u0026#34;: \u0026#34;latest\u0026#34;, 15 \u0026#34;swagger-stats\u0026#34;: \u0026#34;^0.99.7\u0026#34; 16 } 17} This is app.js\nIf you want to use Swagger UI, you can remark line 40-53 and line 55-69\n1\u0026#39;use strict\u0026#39; 2 3const fastify = require(\u0026#39;fastify\u0026#39;)({ 4logger: true 5}); 6 7// Static plugin to render HTML pages 8const path = require(\u0026#39;node:path\u0026#39;) 9fastify.register(require(\u0026#39;@fastify/static\u0026#39;), { 10root: path.join(__dirname, \u0026#39;/public\u0026#39;), 11prefix: \u0026#39;/public/\u0026#39;, // optional: default \u0026#39;/\u0026#39; 12// http://localhost:3000/public/index.html 13// constraints: { host: \u0026#39;example.com\u0026#39; } // optional: default {} 14}) 15 16// Swagger Stats 17const swStats = require(\u0026#39;swagger-stats\u0026#39;); 18const apiSpec = require(\u0026#39;./swagger.json\u0026#39;); 19 20// Register Swagger 21const registerSwagger = async () =\u0026gt; { 22try { 23 await fastify.register(require(\u0026#39;@fastify/swagger\u0026#39;), { 24 // openapi options 25 openapi: { 26 openapi: \u0026#34;3.1.0\u0026#34;, 27 info: { 28 title: \u0026#39;test openapi\u0026#39;, 29 description: \u0026#39;this is a test\u0026#39;, 30 version: \u0026#39;1.0.1\u0026#39;, 31 }, 32 // externalDocs: Object, 33 // servers: [ Object ], 34 // components: Object, 35 // security: [ Object ], 36 // tags: [ Object ] 37 }, 38 39 // Swagger options 40 swagger: { 41 info: { 42 title: \u0026#39;Test swagger\u0026#39;, 43 description: \u0026#39;Testing the Fastify swagger API\u0026#39;, 44 version: \u0026#39;0.1.0\u0026#39; 45 }, 46 externalDocs: { 47 url: \u0026#39;https://swagger.io\u0026#39;, 48 description: \u0026#39;Find more info here\u0026#39; 49 }, 50 host: \u0026#39;localhost\u0026#39;, 51 schemes: [\u0026#39;http\u0026#39;], 52 } 53 }) 54 55 // await fastify.register(require(\u0026#39;@fastify/swagger-ui\u0026#39;), { 56 // routePrefix: \u0026#39;/documentation\u0026#39;, 57 // uiConfig: { 58 // docExpansion: \u0026#39;full\u0026#39;, 59 // deepLinking: false 60 // }, 61 // uiHooks: { 62 // onRequest: function (request, reply, next) { next() }, 63 // preHandler: function (request, reply, next) { next() } 64 // }, 65 // staticCSP: true, 66 // transformStaticCSP: (header) =\u0026gt; header, 67 // transformSpecification: (swaggerObject, request, reply) =\u0026gt; { return swaggerObject }, 68 // transformSpecificationClone: true 69 // }) 70} catch (err) { 71 console.log(err); 72 process.exit(1); 73} 74} 75 76// Register Fastify Route 77const registerRoute = async () =\u0026gt; { 78try { 79 // Define a sample route 80 fastify.get(\u0026#39;/route1\u0026#39;, async (request, reply) =\u0026gt; { 81 return { hello: \u0026#39;world\u0026#39; }; 82 }); 83 84 // Define a sample route 85 fastify.get(\u0026#39;/route2\u0026#39;, async (request, reply) =\u0026gt; { 86 return { hello: \u0026#39;world\u0026#39; }; 87 }); 88 89 // Define a swagger route 90 fastify.get(\u0026#39;/doc\u0026#39;, async (request, reply) =\u0026gt; { 91 return fastify.swagger(); 92 // reply.send(fastify.swagger()) ==\u0026gt; work, but bad, why? 93 }); 94 95 // Enable swagger-stats 96 // fastify.register(require(\u0026#39;fastify-express\u0026#39;)).then(()=\u0026gt;{ 97 fastify.register(require(\u0026#39;@fastify/express\u0026#39;)).then(()=\u0026gt;{ 98 fastify.register(swStats.getFastifyPlugin, {swaggerSpec:apiSpec}); 99 }); 100 101 await fastify.ready() 102 await fastify.listen({ port: 3000 }); 103 104 console.log(`Server listening on ${fastify.server.address().port}`); 105} catch (err) { 106 console.log(err); 107 process.exit(1); 108} 109}; 110 111const main = async () =\u0026gt; { 112console.log(\u0026#34;Start to register Swagger\u0026#34;) 113await registerSwagger(); 114console.log(\u0026#34;Start to register Route\u0026#34;) 115await registerRoute(); 116console.log(\u0026#34;Done\u0026#34;) 117} 118 119main(); If you want to use RapiDoc, you need to add a HTML file\n1\u0026lt;!doctype html\u0026gt; \u0026lt;!-- Important: must specify --\u0026gt; 2\u0026lt;html\u0026gt; 3\u0026lt;head\u0026gt; 4 \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;!-- Important: rapi-doc uses utf8 characters --\u0026gt; 5 \u0026lt;script type=\u0026#34;module\u0026#34; src=\u0026#34;rapidoc-min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 6\u0026lt;/head\u0026gt; 7\u0026lt;body\u0026gt; 8 \u0026lt;rapi-doc spec-url = \u0026#34;http://localhost:3000/doc\u0026#34;\u0026gt; \u0026lt;/rapi-doc\u0026gt; 9\u0026lt;/body\u0026gt; 10\u0026lt;/html\u0026gt; Result OpenAPI json: http://localhost:3000/doc RapiDoc: http://localhost:3000/public/index.html Swagger UI: http://localhost:3000/documentation/ Swagger statistics: http://localhost:3000/swagger-stats/ What's next Consider to try Elements\n","link":"https://dennys.github.io/en/doc/javascript/node-openapi/","section":"doc","tags":["Node","JavaScript"],"title":"Node + FastAPI + OpenAPI + Statistics"},{"body":"","link":"https://dennys.github.io/en/series/","section":"series","tags":null,"title":"Series"},{"body":"","link":"https://dennys.github.io/en/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://dennys.github.io/en/tags/dotnet/","section":"tags","tags":null,"title":"dotNet"},{"body":"","link":"https://dennys.github.io/en/series/dotnet/","section":"series","tags":null,"title":"dotNet"},{"body":"Reqruiement I have two view models - MainViewModel and OptionViewModel -, that share a common component CustomConfiguration. My goal is to load the data into MainViewModel in MainWindow, and when the Option button ic clicked on MainWindow, OptionWindow will be opened, and the CustomConfiguration data will be passed into it.\nCode MainWindow.xaml Only bind a data (CustomConfig.GeneralSettings.IsLogEnabled) and assign the command.\n1\u0026lt;Window.DataContext\u0026gt; 2 \u0026lt;local:MainViewModel /\u0026gt; 3\u0026lt;/Window.DataContext\u0026gt; 4\u0026lt;StackPanel\u0026gt; 5 \u0026lt;TextBlock Text=\u0026#34;{Binding CustomConfig.GeneralSettings.IsLogEnabled}\u0026#34; /\u0026gt; 6 \u0026lt;Button Content=\u0026#34;Open Options\u0026#34; Command=\u0026#34;{Binding OpenOptionsCommand}\u0026#34; /\u0026gt; 7\u0026lt;/StackPanel\u0026gt; OptionWindow.xaml The same as MainWindow.xaml, only bind a data (CustomConfig.GeneralSettings.IsLogEnabled) and assign the command.\n1\u0026lt;Window.DataContext\u0026gt; 2 \u0026lt;local:OptionViewModel /\u0026gt; 3\u0026lt;/Window.DataContext\u0026gt; 4\u0026lt;StackPanel\u0026gt; 5 \u0026lt;CheckBox Content=\u0026#34;Enable Logging\u0026#34; IsChecked=\u0026#34;{Binding CustomConfig.GeneralSettings.IsLogEnabled}\u0026#34; /\u0026gt; 6 \u0026lt;Button Content=\u0026#34;OK\u0026#34; Command=\u0026#34;{Binding OKCommand}\u0026#34; /\u0026gt; 7\u0026lt;/StackPanel\u0026gt; MainWindow.xaml.cs No special commands here.\n1public partial class MainWindow : Window { 2 public MainWindow() { 3 InitializeComponent(); 4 } 5} OptionWindow.xaml.cs No special commands here.\n1public partial class OptionWindow : Window { 2 public OptionWindow() { 3 InitializeComponent(); 4 } 5} OptionWindow.xaml.cs =\u0026gt; If you want to clone data. In the previous version, the CustomConfiguration instance was passed from MainViewModel into OptionViewModel, so they share one instance. If you want to create a copy of CustomConfiguration in OptionViewModel, you can use this constructor.\n1 public OptionWindow(CustomConfiguration config) { 2 InitializeComponent(); 3 4 //_initialConfig = config; 5 _viewModel = new OptionViewModel(config.Clone()); 6 DataContext = _viewModel; 7 } CustomConfiguration.cs 1public class CustomConfiguration : INotifyPropertyChanged { 2 private GeneralSettingsClass _generalSettings = new GeneralSettingsClass(); 3 4 public GeneralSettingsClass GeneralSettings { 5 get =\u0026gt; _generalSettings; 6 set { 7 _generalSettings = value; 8 OnPropertyChanged(); 9 } 10 } 11 12 public event PropertyChangedEventHandler PropertyChanged; 13 protected virtual void OnPropertyChanged([CallerMemberName] string propertyName = null) { 14 PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName)); 15 } 16} 17 18public class GeneralSettingsClass : INotifyPropertyChanged { 19 private bool _isLogEnabled = false; 20 21 public bool IsLogEnabled { 22 get =\u0026gt; _isLogEnabled; 23 set { 24 _isLogEnabled = value; 25 OnPropertyChanged(); 26 } 27 } 28 29 public event PropertyChangedEventHandler PropertyChanged; 30 protected virtual void OnPropertyChanged([CallerMemberName] string propertyName = null) { 31 PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName)); 32 } 33} MainViewModel.cs Please remember to check the Shared variable, if you want to share one instance of CustomConfiguration, you can set it to true. If you want to create a copy of CustomConfiguation, you can set it to false.\n1public class MainViewModel : INotifyPropertyChanged { 2 public CustomConfiguration CustomConfig { get; } = new CustomConfiguration(); 3 4 public RelayCommand OpenOptionsCommand { get; } 5 6 public MainViewModel() { 7 OpenOptionsCommand = new RelayCommand(OpenOptionsCommandExecute); 8 } 9 10 private void OpenOptionsCommandExecute() { 11 bool Shared = false; 12 if (Shared) { 13 // This ViewModel will be shared 14 var optionViewModel = new OptionViewModel(CustomConfig); 15 var optionWindow = new OptionWindow() { DataContext = optionViewModel }; 16 optionWindow.ShowDialog(); 17 } else { 18 // This ViewModel will be cloned 19 var optionWindow = new OptionWindow(CustomConfig.Clone()); 20 optionWindow.ApplyChanges += (s, config) =\u0026gt; { 21 this.CustomConfig = config; 22 }; 23 optionWindow.ShowDialog(); 24 } 25 } 26 27 public event PropertyChangedEventHandler PropertyChanged; 28 protected virtual void OnPropertyChanged([CallerMemberName] string propertyName = null) { 29 PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName)); 30 } 31} OptionViewModel.cs 1public class OptionViewModel : INotifyPropertyChanged { 2 private CustomConfiguration _customConfig; 3 4 public CustomConfiguration CustomConfig { 5 get =\u0026gt; _customConfig; 6 set { 7 _customConfig = value; 8 OnPropertyChanged(); 9 } 10 } 11 12 public RelayCommand OKCommand { get; } 13 14 public OptionViewModel(CustomConfiguration customConfig) { 15 CustomConfig = customConfig; 16 OKCommand = new RelayCommand(OKCommandExecute); 17 } 18 19 private void OKCommandExecute() { 20 CustomConfig.Save(); 21 // Close the option window 22 (Application.Current.MainWindow as Window)?.Close(); 23 } 24 25 public event PropertyChangedEventHandler PropertyChanged; 26 protected virtual void OnPropertyChanged([CallerMemberName] string propertyName = null) { 27 PropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName)); 28 } 29} Test Case 1: share one instance Run the program. Click OpenOptions button. Click Enable Logging check box. You shuold see the flag in MainWindow is switched. Case 2: Not share one instance (create a copy) Set Shared to false in MainViewModel.cs. Run the program. Click OpenOptions button. Click Enable Logging check box. You shuold see the flag in MainWindow is NOT changed. ","link":"https://dennys.github.io/en/doc/dotnet/sharing-components-between-two-view-models-in-csharp-mvvm/","section":"doc","tags":["dotNet"],"title":"Sharing components between two view models in C# MVVM"},{"body":"","link":"https://dennys.github.io/en/tags/google-photos/","section":"tags","tags":null,"title":"Google Photos"},{"body":"I'm trying to search my photos in Google Photos by device name (iPhone or Google Pixel or ...), but it's weird. I have a Google Pixel 5, when I try to search for Google Pixel 5, I can get all the photos taken by it, but when I just type Google Pixel to search, it only shows partial photos. I'm not sure about Google's search algorithm, I just record my test results.\nApple iPhone 6 Apple iPhone 11 Apple iPhone XS Max Apple iPad (6th generation) Google Pixel 5 Samsung SM-M135F (Samsung Galaxy M13) Samsung SM-G935F (Samsung S7 edge) Panasonic DMC-G6 Panasonic DMC-G2 SONY DSC-RX100M5A By the way, you can use Apple, Google, and Samsung to find their devices, but it will search for some other photos. For example, if your photo is a Samsung refrigerator, it will be included in the search results.\nReference:\nhttps://support.google.com/photos/thread/368298/how-to-search-google-photos-by-which-device-took-the-picture?hl=en ","link":"https://dennys.github.io/en/doc/software/google-photos-search-by-device/","section":"doc","tags":["Software","Google Photos"],"title":"Search Google Photos by Device"},{"body":"","link":"https://dennys.github.io/en/tags/software/","section":"tags","tags":null,"title":"Software"},{"body":"Requirement Try to find software that can search or replace text in files, and it should support these functions:\nFree software. Supports UTF-8. It can show partial find content in the search result (or it takes a long time to see the file content). Double click can open the file with the associated editor. Supports replace. As fast as possible (of course) Software comparison Compare 3 software, I prefer to use grepWin.\ngrepWin SearchMyFiles Find and Replace (FNR) grepWin SearchMyFiles Find and Replace (FNR) GitHub star 1.3K N/A N/A UTF-8 Yes Yes (*R1) Yes Show file content Yes (in a column) Yes (in a column) Yes (in another panel) Double click open file Yes Yes (*R2) Yes Replace Yes Yes Yes Speed Fast Fast R1: SearchMyFiles' UTF-8 support is strange, if you try to search a UTF-8 word (e.g. a Chinese word), it can search and display the content. However, if you search for an English word (but the content has some other Chinese words), it will display garbled in the content. R2: The default behavior of double click in SearchMyFiles is to open a window to show file properties, you can change the associated editor using Options -\u0026gt; Double-Click. ","link":"https://dennys.github.io/en/doc/software/file-search-and-replace-tool/","section":"doc","tags":["Software"],"title":"File Search/Replace Tool"},{"body":"","link":"https://dennys.github.io/en/tags/android/","section":"tags","tags":null,"title":"Android"},{"body":"","link":"https://dennys.github.io/en/series/android-%E4%BD%BF%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/","section":"series","tags":null,"title":"Android 使用小技巧"},{"body":"Requirement In Gmail's default notification actions, you can choose to Archive or Reply . But you can change it.\nSolution Open the Gmail App's General setting, change the *Default email notification action\u0026quot;. The default action is Archive, but you can change it to Delete. After configuring, you will be able to delete emails in Gmail's notification. What's next It's better to enable both Archive and Delete in the notification.\n","link":"https://dennys.github.io/en/doc/android/gmail-notify-delete-archive/","section":"doc","tags":["Android"],"title":"How to Change the Gmail Notification Action from Archive to Delete"},{"body":"Requirement In the previous article, we know we can change archive to delete in the Email(Gmail) notification of Android (Reference: http://dennys.github.io/en/doc/android/gmail-notify-delete-archive/) But we cannot enable BOTH, therefore, I try to find a solution in other Apps.\nK-9 Mail, ( K-9 Mail Joins The Thunderbird Family ) FairEmail Gmail Let's check Gmail's ability, the default action is Archive. Open the Gmail App's General setting, and change the *Default email notification action\u0026quot;. The default action is Archive, you can change it to Delete. After the configuration, you can delete mail in Gmail's notification. K9 K9 offers the actions Reply, Mark Read, Delete actions, but doesn't offer the action Archive. FairEmail In FairEmail, the default actions are Trash Can and Mark Read You can select Notification actions in the Settings, and you can select at most 3 actions in the free version. ","link":"https://dennys.github.io/en/doc/android/android-gmail-notification-actions/","section":"doc","tags":["Android"],"title":"Android Gmail Notification Actions (Archive, Delete, ...)"},{"body":"","link":"https://dennys.github.io/en/tags/.net/","section":"tags","tags":null,"title":".NET"},{"body":"","link":"https://dennys.github.io/en/categories/devops/","section":"categories","tags":null,"title":"DevOps"},{"body":"","link":"https://dennys.github.io/en/tags/gitlab/","section":"tags","tags":null,"title":"GitLab"},{"body":"","link":"https://dennys.github.io/en/series/gitlab-devops/","section":"series","tags":null,"title":"GitLab DevOps"},{"body":"If you want to use SonarQube to scan your code during GitLab's CI/CD flow, please see the following procedures.\nGitLab + SonarQube + .NET Core or .NET 5/6/7/... (docker) Refer to this document to integrate GitLab and SonarQube.\nSet the environment variable in GitLab\n$SONAR_URL: The URL of SonarQube $SONAR_TOKEN: The token to access SonarQube $CI_PROJECT_DIR: This is a predifined variable in GitLab, you can reference https://docs.gitlab.com/ee/ci/variables/predefined_variables.html $CI_JOB_NAME: This is a predifined variable in GitLab, you can reference https://docs.gitlab.com/ee/ci/variables/predefined_variables.html Add the following to your .gitlab-ci.yml\n1variables: 2 SONAR_PROJECT_KEY: This-is-my-project-key-in-SonarQube 3 4owasp_dependency_check: 5 image: 6 name: registry.gitlab.com/gitlab-ci-utils/docker-dependency-check:latest 7 entrypoint: [\u0026#34;\u0026#34;] 8 stage: dependency_check 9 tags: 10 - docker 11 script: 12 # Job will scan the project root folder and fail if any vulnerabilities with CVSS \u0026gt; 0 are found 13 - /usr/share/dependency-check/bin/dependency-check.sh --scan \u0026#34;./\u0026#34; --format ALL --project \u0026#34;$CI_PROJECT_NAME\u0026#34; --failOnCVSS 0 14 # Dependency Check will only fail the job based on CVSS scores, and in some cases vulnerabilities do not 15 # have CVSS scores (e.g. those from NPM audit), so they don\u0026#39;t cause failure. To fail for any vulnerabilities 16 # grep the resulting report for any \u0026#34;vulnerabilities\u0026#34; sections and exit if any are found (count \u0026gt; 0). 17 - if [ $(grep -c \u0026#34;vulnerabilities\u0026#34; dependency-check-report.json) -gt 0 ]; then exit 2; fi 18 allow_failure: true 19 artifacts: 20 when: always 21 paths: 22 # Save the HTML and JSON report artifacts 23 - \u0026#34;./dependency-check-report.html\u0026#34; 24 - \u0026#34;./dependency-check-report.json\u0026#34; 25 26sonarqube: 27 allow_failure: true 28 stage: sonar 29 tags: 30 - docker 31 image: 32 name: sonarsource/sonar-scanner-cli:latest 33 entrypoint: [\u0026#34;\u0026#34;] 34 variables: 35 SONAR_HOST_URL: $SONAR_URL 36 SONAR_USER_HOME: \u0026#34;${CI_PROJECT_DIR}/.sonar\u0026#34; # Defines the location of the analysis task cache 37 #SONAR_LOGIN: $SONAR_TOKEN 38 GIT_DEPTH: \u0026#34;0\u0026#34; # Tells git to fetch all the branches of the project, required by the analysis task 39 cache: 40 key: \u0026#34;${CI_JOB_NAME}\u0026#34; 41 paths: 42 - .sonar/cache 43 script: 44 - echo $SONAR_URL 45 - echo $CI_COMMIT_BRANCH 46 - sonar-scanner -D sonar.login=\u0026#34;$SONAR_TOKEN\u0026#34; -D sonar.projectKey=$SONAR_PROJECT_KEY -Dsonar.projectName=\u0026#34;${SONAR_PROJECT_KEY} (${CI_COMMIT_BRANCH})\u0026#34; 47 -D sonar.dependencyCheck.jsonReportPath=\u0026#34;./dependency-check-report.json\u0026#34; -D sonar.dependencyCheck.htmlReportPath=\u0026#34;./dependency-check-report.html\u0026#34; 48 49security-code-scan: 50 stage: security-scan 51 tags: 52 - docker 53 allow_failure: true 54 image: mcr.microsoft.com/dotnet/sdk:5.0 55 #image: mcr.microsoft.com/dotnet/core/sdk:3.1 56 script: 57 - echo $env:Path 58 - dotnet restore 59 - dotnet tool install --global security-scan 60 - mkdir report 61 - $HOME/.dotnet/tools/security-scan geosense_netcore_project_template.sln --excl-proj=**/*Test*/** --export=report/out.sarif 62 artifacts: 63 paths: 64 - ./geosense_netcore_project_template/report Try to build the code\nGitLab + SonarQube + .NET 4.8 (non-docker) The docker support of .NET 4.0 or below is not very good, if you cannot upgrade, I suggest you use non-docker solution. You can refer to http://dennys.github.io/en/doc/devops/gitlab-dotnet4-ci-cd/ to build .NET 4 applications in GitLab CI/CD flow. And you can follow the following procedures to integrate SonarQube.\nReference this document to integrate GitLab and SonarQube. You need to install these softwares: Java, you can choose Adopt JDK or others, please add java.exe to PATH. Sonar Scanner for .NET, assumes you put it in C:\\Gitlab\\sonar-scanner. Add the following to your .gitlab-ci.yml 1sonarqube_windows: 2 allow_failure: true 3 tags: 4 - windows 5 stage: sonar 6 variables: 7 SONAR_PROJECT_KEY: ProjectXXX 8 SONAR_TOKEN: **************************************** 9 script: 10 - echo $SONAR_URL 11 - echo $CI_COMMIT_BRANCH 12 - dotnet tool update --global dotnet-sonarscanner 13 - dotnet C:\\Gitlab\\sonar-scanner\\SonarScanner.MSBuild.dll begin /k:$SONAR_PROJECT_KEY /d:sonar.host.url=\u0026#34;$SONAR_URL\u0026#34; /d:sonar.login=\u0026#34;$SONAR_TOKEN\u0026#34; /d:sonar.scm.provider=git 14 - dotnet restore ******.sln 15 - dotnet build ******.sln 16 - dotnet C:\\Gitlab\\sonar-scanner\\SonarScanner.MSBuild.dll end /d:sonar.login=\u0026#34;$SONAR_TOKEN\u0026#34; Try to build the code ","link":"https://dennys.github.io/en/doc/devops/gitlab-sonarqube-integration-dotnet/","section":"doc","tags":["GitLab","SonarQube",".NET","CI/CD"],"title":"GitLab SonarQube Integration with .NET"},{"body":"","link":"https://dennys.github.io/en/tags/sonarqube/","section":"tags","tags":null,"title":"SonarQube"},{"body":"","link":"https://dennys.github.io/en/tags/prometheus/","section":"tags","tags":null,"title":"Prometheus"},{"body":" Requirement I have 3 Prometheus servers and want to consolidate all of them into 1 Grafana. And one VM (Server C) is in a restricted zone and this zone only allows a special firewall rule from this zone to other zones.\nPrometheus A pulls (receives) metrics from Prometheus B In this scenario, we use the Federation feature to pull metrics from another Prometheus. You don't need to make any changes to Prometheus B, just add a new job to prometheus.yml of Prometheus A.\nPlease check lines 13~15, you can only pull some metrics you need.\n1# prometheus.yml of A 2 - job_name: \u0026#39;federate\u0026#39; 3 scrape_interval: 15s 4 honor_labels: true 5 metric_relabel_configs: 6 - source_labels: [id] 7 regex: \u0026#39;^static-agent$\u0026#39; 8 action: drop 9 metrics_path: \u0026#39;/federate\u0026#39; 10 params: 11 \u0026#39;match[]\u0026#39;: 12 #- \u0026#39;{job=\u0026#34;prometheus\u0026#34;}\u0026#39; 13 #- \u0026#39;{__name__=~\u0026#34;job:.*\u0026#34;}\u0026#39; 14 - \u0026#39;{__name__=~\u0026#34;node_.*|container_.*\u0026#34;}\u0026#39; 15 - \u0026#39;{__name__=~\u0026#34;windows_.*\u0026#34;}\u0026#39; 16 - \u0026#39;{__name__=~\u0026#34;probe_.*\u0026#34;}\u0026#39; 17 #- \u0026#39;{job!=\u0026#34;\u0026#34;}\u0026#39; 18 #- \u0026#39;{job=\u0026#34;node\u0026#34;}\u0026#39; 19 #- \u0026#39;{job=\u0026#34;blackbox_http_2xx\u0026#34;}\u0026#39; 20 #- \u0026#39;{job=\u0026#34;blackbox_icmp\u0026#34;}\u0026#39; 21 #match[]={__name__=~\u0026#34;..*\u0026#34;} 22 #match[]=\u0026#34;{__name__=~\u0026#34;.+\u0026#34;}\u0026#34; 23 static_configs: 24 - targets: 25 - \u0026#39;x.x.x.x:9090\u0026#39; 26 basic_auth: 27 username: \u0026#39;********\u0026#39; 28 password: \u0026#39;********\u0026#39; Sanity Check: You can connect to http://x.x.x.x:9090/targets and find the federation job status. Prometheus C pushes (forwards) metrics to Prometheus A In this scenario, you first need to enable the Remote Write Receiver feature in Prometheus A. You just need to add --web.enable-remote-write-receiver to your docker-compose.yml, no need to modify prometheus.yml\n1# prometheus.yml of A 2 prometheus: 3 image: prom/prometheus:latest 4 container_name: prometheus 5 expose: 6 - 9090 7 ports: 8 - 9090:9090 9 volumes: 10 - /opt/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro 11 - /opt/prometheus/web.yml:/etc/prometheus/web.yml:ro 12 command: 13 - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; 14 - \u0026#39;--web.config.file=/etc/prometheus/web.yml\u0026#39; 15 - \u0026#39;--web.enable-remote-write-receiver\u0026#39; Then, you need to modify docker-compose.yml and *prometheus.yml of Prometheus C. First, you need to enable Prometheus agent mode, just need to add --enable-feature=agent to docker-compose.yml.\n1# docker-compose.yml of C 2 prometheus: 3 image: prom/prometheus:latest 4 container_name: prometheus 5 expose: 6 - 9090 7 ports: 8 - 9090:9090 9 volumes: 10 - /opt/grafana/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro 11 command: 12 - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; 13 - \u0026#39;--enable-feature=agent\u0026#39; 14 - \u0026#39;--log.level=debug\u0026#39; Second, you need to edit prometheus.yml, add the remote_write section, and enter the URL of Prometheus A in it.\n1# prometheus.yml of C 2global: 3 scrape_interval: 15s 4 5remote_write: 6 - url: \u0026#39;http://(Domain of Prometheus A):9090/api/v1/write\u0026#39; 7 basic_auth: 8 username: \u0026#39;******\u0026#39; 9 password: \u0026#39;******\u0026#39; Sanity check: you can enable the log to debug level and check that it's sending the data.\n1prometheus | ts=2022-08-31T06:58:46.065Z caller=dedupe.go:112 component=remote level=debug remote_name=3c577a url=http://x.x.x.x:3128/api/v1/write msg=QueueManager.calculateDesiredShards dataInRate=95.10224000000001 dataOutRate=273.83119999999997 dataKeptRatio=1 dataPendingRate=-178.72895999999997 dataPending=285.30672000000004 dataOutDuration=0.026267519444000003 timePerSample=9.592595527463637e-05 desiredShards=0.010491189203871395 highestSent=1.66192912e+09 highestRecv=1.661929123e+09 Note You should enable authentication in Prometheus, you can refer to this page to hash your password https://prometheus.io/docs/guides/basic-auth/, and save it in your web.yml.\n1basic_auth_users: 2 username: ****************************************** Port forward If you have a restricted firewall, you can use socat to forward the request to another host.\n1socat -v TCP-LISTEN:3128,fork,reuseaddr TCP:x.x.x.x:9090 ","link":"https://dennys.github.io/en/doc/grafana/prometheus-pulls-pushes-metrics/","section":"doc","tags":["Prometheus"],"title":"Prometheus Pulls/Pushes Metrics from/to Another Prometheus"},{"body":"","link":"https://dennys.github.io/en/tags/openwrt/","section":"tags","tags":null,"title":"OpenWrt"},{"body":"Requirement Find a bandwidth management tool in OpenWrt to see which application (by interface) uses the most bandwidth.\nOpenWrt solution There are lots of bandwidth monitor tools in OpenWrt... https://openwrt.org/docs/guide-user/services/network_monitoring/bwmon#available_tools\ncollectd collectd is not just for network only, it's a common data collection tool in the UNIX platform. We can use collectd's network related plugins here.\nWebsite:\nOfficial website: https://openwrt.org/docs/guide-user/perf_and_log/statistic.collectd GitHub: https://github.com/collectd/collectd Installation: just install luci-app-statistics and it will include related libraries.\n1opkg install luci-app-statistics Usage\nConnect to Menu: Statistics -\u0026gt; Setup -\u0026gt; Network plugins, configure the plugin of the Interface or Wireless. Click Statistics -\u0026gt; Setup -\u0026gt; Graphs, and you can see the charts. vnStat: old brand, only for network Website:\nOfficial website: https://humdi.net/vnstat/ GitHub: https://github.com/vergoh/vnstat Installation\n1opkg install vnstat2 vnstati2 luci-app-vnstat2 Warning: vnstat1 and vnstat2 are not compatible, if you want to remove vnstat 1.x, please run the following commands:\n1opkg remove vnstat vnstati luci-app-vnstat 2rm /etc/vnstat.conf 3rm /etc/config/vnstat Usage\nConnect to http://192.168.1.1/cgi-bin/luci/admin/status/vnstat2 You can google some sample reports generated by vnStat https://www.google.com/search?q=vnstat+openwrt\u0026amp;sxsrf=ALiCzsZM_jTIfojSOXzoTYU9g9BBB7h96A:1658385561017\u0026amp;source=lnms\u0026amp;tbm=isch\u0026amp;sa=X\u0026amp;ved=2ahUKEwiPhY_Sr4n5AhV-qFYBHWulCg8Q_AUoAXoECAEQAw\u0026amp;biw=1920\u0026amp;bih=969\u0026amp;dpr=1 bandwidthd (stop maintenance) Website\nOfficial website(new): https://openwrt.org/docs/guide-user/services/network_monitoring/bandwidthd Official website(old): http://bandwidthd.sourceforge.net/ GitHub: https://github.com/NethServer/bandwidthd (stop maintenance) Installation: just follow the instructions of the official website\nUsage\nConnect to http://192.168.1.1/bandwidthd/ You can see the traffic of all IP addresses (The following charts are embedded from the official website) Note\nIt only provides network traffic by protocol, not enough. It runs several processes in the router, you can run top to check them. 1PID PPID USER STAT VSZ %VSZ %CPU COMMAND 24049 4046 root S 5220 4% 0% /usr/sbin/bandwidthd 34046 1 root S 5220 4% 0% /usr/sbin/bandwidthd 44048 4046 root S 5220 4% 0% /usr/sbin/bandwidthd 54050 4046 root S 5196 4% 0% /usr/sbin/bandwidthd ","link":"https://dennys.github.io/en/doc/router/openwrt-bandwidth-by-interface/","section":"doc","tags":["OpenWrt","改機","Router"],"title":"OpenWrt Bandwidth Management (by interface) "},{"body":"","link":"https://dennys.github.io/en/series/openwrt-%E6%94%B9%E6%A9%9F/","section":"series","tags":null,"title":"OpenWrt 改機"},{"body":"","link":"https://dennys.github.io/en/tags/router/","section":"tags","tags":null,"title":"Router"},{"body":"","link":"https://dennys.github.io/en/tags/%E6%94%B9%E6%A9%9F/","section":"tags","tags":null,"title":"改機"},{"body":"","link":"https://dennys.github.io/en/series/android-tips/","section":"series","tags":null,"title":"Android Tips"},{"body":"\rNotice\rThis solution is only for Android 11 or below!!! Please use Better Open With in Android 12 or above. Requirement Android's default YouTube App is not very convenient, there are lots of Open Source alternatives (YouTube Vanced (removed), NewPipe, ...), although you can install them, if you don't change the default YouTube App, it's still inconvenient.\nSolution Android Settings -\u0026gt; Apps -\u0026gt; Default apps -\u0026gt; Opening links\nIt will list all Apps, choose YouTube, and you will see the following screen. Disable \u0026quot;Open supported links\u0026quot;. Return to the previous menu, choose your preferred YouTube App, I use NewPipe, and choose * + Add link*. Enable YouTube related 4 links. Return to the previous menu, you can see NewPipe connects to the 4 links. FAQ If you find you cannot change it, you may forget to disable them on YouTube. Because a link can only link to 1 App. Result You can try to use Chrome to find some videos, try to open them and it will use NewPipe (or your preferred App) to open. ","link":"https://dennys.github.io/en/doc/android/android-modify-default-youtube-app/","section":"doc","tags":["Android","YouTube"],"title":"How to Change Default YouTube App (YouTube Vanced, NewPipe, ...) in Android"},{"body":"","link":"https://dennys.github.io/en/tags/youtube/","section":"tags","tags":null,"title":"YouTube"},{"body":"","link":"https://dennys.github.io/en/tags/grafana/","section":"tags","tags":null,"title":"Grafana"},{"body":"Requirement Usually we use SonarQube to check the KPI of projects: You can also check the build history of a project: Use Grafana to Manager SonarQube KPI But there are some SonarQube exporters, they can export SonarQube's KPI to Grafana/Prometheus.\nSolution 1 Exporter: https://github.com/dmeiners88/sonarqube-prometheus-exporter: It's a SonarQube plugin, but it only supports 5 KPIs, and the last commit date is 2018/11/9. It supports SonarQube 7, not sure if it supports 8 or 9, I don't plan to try it. Solution 2 Exporter: https://github.com/nthienan/sonarqube-exporter Grafana dashboard: you can find 2s dashboard overview.json and dashboard details.json on this GitHub. Generate a SonarQube token, you can reference https://docs.sonarqube.org/latest/user-guide/user-token/ How to start this exporter You can run this command directly: 1docker run --expose 9102 -p 9102:9102 nthienan/sonarqube-exporter sqe -p 9102 --url http://sonar.x.x.x:9000 --user-token xxxxxxxxxxx --ignore-ssl-verification --log-level DEBUG If you use docker-compose, you can reference this docker-compose.yml 1sonarqube-exporter: 2container_name: sonarqube-exporter 3image: nthienan/sonarqube-exporter 4ports: 5- 9102:9102 6expose: 7- 9102 8command: \u0026#39; sqe -p 9102 --url http://sonar.x.x.x:9000 --user-token xxxxxxxxxxx --ignore-ssl-verification --log-level DEBUG \u0026#39; 9environment: 10- TZ=Asia/Taipei 11depends_on: 12- sonarqube prometheus.yml 1- job_name: \u0026#39;sonarqube\u0026#39; 2 scrape_interval: 5s 3 metrics_path: \u0026#39;/metrics\u0026#39; 4 static_configs: 5 - targets: [\u0026#39;xxx.xxx.xxx.xxx:9102\u0026#39;] Result Restart Prometheus and rebuild the project, and you can see the result in Grafana.\nYou can also check the detail dashboard, it contains more information like a build trend chart. The following is not a google sample, I'll update it in the future.\n","link":"https://dennys.github.io/en/doc/devops/grafana-sonarqube-integration/","section":"doc","tags":["SonarQube","CI/CD","Grafana"],"title":"Use Grafana to Manager SonarQube KPI"},{"body":"Change log 2022/10/13: Add some check points. Requirement When there are lots of projects on GitLab, it's not easy to know the overall build status of their CI/CD Pipelines.\nUse Grafana to Manage GitLab CI/CD Pipelines Solution 1: Use GitLab build-in metrics Exporter: GitLab build-in (reference: https://docs.gitlab.com/ee/administration/monitoring/prometheus/) Grafana dashboard: https://grafana.com/grafana/dashboards/10620 This dashboard needs this plugin: https://grafana.com/grafana/plugins/grafana-polystat-panel/ prometheus.yml 1- job_name: \u0026#39;GitLab\u0026#39; 2 scrape_interval: 5s 3 metrics_path: \u0026#39;/-/metrics\u0026#39; 4 scheme: https 5 static_configs: 6 - targets: [\u0026#39;gitlab.xxx.xxx.xxx\u0026#39;] 7 params: 8 token: [\u0026#39;***************\u0026#39;] Solution 2: Use gitlab-ci-pipelines-exporter Exporter: https://github.com/mvisonneau/gitlab-ci-pipelines-exporter This exporter provides several spectives metrics (with different Grafana dashboards) Grafana dashboard: the same as solution 1 (it also needs Ploystat plugin)\nHow to start gitlab-ci-pipelines-exporter\nAssume you put gitlab-ci-pipelines-exporter's configuration at /opt/grafana/gitlab-ci-pipelines-exporter/gitlab-ci-pipelines-exporter.yml\n1server: 2# [address:port] to make the process listen 3# upon (optional, default: :8080) 4listen_address: :9103 5gitlab: 6url: https://gitlab.xxx.xxx.xxx/ 7# You can also configure the token using --gitlab-token 8# or the $GCPE_GITLAB_TOKEN environment variable 9token: xrN14n9-ywvAFxxxxxx 10project_defaults: 11pull: 12 pipeline: 13 jobs: 14 enabled: true 15 environments: 16 enabled: true 17 18wildcards: 19- owner: 20 name: g1 21 kind: group 22 include_subgroups: true You can run this command to start this exporter in docker\n1docker run --restart always \\ 2--name gitlab-ci-pipelines-exporter \\ 3-v /opt/gitlab-runner/gitlab-ci-pipelines-exporter.yml:/etc/config.yml \\ 4-v /etc/hosts:/etc/hosts \\ 5--expose 9103 \\ 6-p 9103:9103 \\ 7mvisonneau/gitlab-ci-pipelines-exporter:v0.5.3 \\ 8run --config /etc/config.yml If you use docker-compose, you can reference the following yml\n1gitlab-ci-pipelines-exporter: 2image: mvisonneau/gitlab-ci-pipelines-exporter:v0.5.3 3container_name: gitlab-ci-pipelines-exporter 4ports: 5- 9103:9103 6expose: 7- 9103 8volumes: 9- /opt/grafana/gitlab-ci-pipelines-exporter/gitlab-ci-pipelines-exporter.yml:/etc/gitlab-ci-pipelines-exporter.yml 10- /etc/hosts:/etc/hosts 11environment: 12 GCPE_CONFIG: /etc/gitlab-ci-pipelines-exporter.yml 13 #GCPE_GITLAB_TOKEN: ${GCPE_GITLAB_TOKEN} 14 #GCPE_INTERNAL_MONITORING_LISTENER_ADDRESS: tcp://127.0.0.1:8082 How to check: You can connect to http://your.server:9103/metrics, and you should see some metrics start like \u0026quot;gitlab_ci_pineline_xxxx\u0026quot; If you only see metrics like \u0026quot;gcpe_projects_***\u0026quot; and \u0026quot;promhttp_metric_handler_errors_total\u0026quot;, you may need to check your configuration.\n1# TYPE gitlab_ci_pipeline_coverage gauge 2gitlab_ci_pipeline_coverage{kind=\u0026#34;branch\u0026#34;,project=\u0026#34;******\u0026#34;,ref=\u0026#34;master\u0026#34;,topics=\u0026#34;\u0026#34;,variables=\u0026#34;\u0026#34;} 0 3gitlab_ci_pipeline_coverage{kind=\u0026#34;branch\u0026#34;,project=\u0026#34;******\u0026#34;,ref=\u0026#34;master\u0026#34;,topics=\u0026#34;\u0026#34;,variables=\u0026#34;\u0026#34;} 0 4# HELP gitlab_ci_pipeline_duration_seconds Duration in seconds of the most recent pipeline 5# TYPE gitlab_ci_pipeline_duration_seconds gauge 6gitlab_ci_pipeline_duration_seconds{kind=\u0026#34;branch\u0026#34;,project=\u0026#34;******\u0026#34;,ref=\u0026#34;master\u0026#34;,topics=\u0026#34;\u0026#34;,variables=\u0026#34;\u0026#34;} 253 7gitlab_ci_pipeline_duration_seconds{kind=\u0026#34;branch\u0026#34;,project=\u0026#34;******\u0026#34;,ref=\u0026#34;master\u0026#34;,topics=\u0026#34;\u0026#34;,variables=\u0026#34;\u0026#34;} 489 8# HELP gitlab_ci_pipeline_id ID of the most recent pipeline 9# TYPE gitlab_ci_pipeline_id gauge 10gitlab_ci_pipeline_id{kind=\u0026#34;branch\u0026#34;,project=\u0026#34;******\u0026#34;,ref=\u0026#34;master\u0026#34;,topics=\u0026#34;\u0026#34;,variables=\u0026#34;\u0026#34;} 811 11gitlab_ci_pipeline_id{kind=\u0026#34;branch\u0026#34;,project=\u0026#34;******\u0026#34;,ref=\u0026#34;main\u0026#34;,topics=\u0026#34;\u0026#34;,variables=\u0026#34;\u0026#34;} 823 12...... prometheus.yml\n1- job_name: \u0026#39;gitlab-runner-ci-pipeline\u0026#39; 2 metrics_path: \u0026#39;/metrics\u0026#39; 3 scrape_interval: 5s 4 scheme: http 5 bearer_token: bearer_token 6 static_configs: 7 - targets: [\u0026#39;xxx.xxx.xxx.xxx:9103\u0026#39;] Result\nSolution 1 and 2 use the same dashboard, like the following: And you can click the ID, it will forward to GitLab's CI/CD Pipelines, you can see every jobs' execution status. Job status of CI Pipelines The above solution is to check the entire CI pipeline results, if you want to see individual job status in Grafana, you can modify gitlab-ci-pipelines-exporter.yml to add lines 5~6. And you can install this Grafana dashboard https://grafana.com/grafana/dashboards/13328\n1# Pull jobs related metrics on all projects 2project_defaults: 3pull: 4 pipeline: 5 jobs: 6 enabled: true Result\nYou can see every job's execution time and result, and you can click ID to see the detail in GitLab. Environments / Deployments status I don't try it yet, you can reference https://grafana.com/grafana/dashboards/13329\n","link":"https://dennys.github.io/en/doc/devops/grafana-gitlab-integration/","section":"doc","tags":["GitLab","CI/CD","Grafana"],"title":"Use Grafana to Manage GitLab CI/CD Pipelines"},{"body":"K-9 Mail 6.200 is released on 2022/07/08, it add the support to OAuth 2.0. Before it, if you activated the 2-factor verification on your Google account, when you try to use K-9 mail to connect to Gmail, you need to use App Passwords. It's not convenient, you can reference https://ekiwi-blog.de/en/16841/ to check the detail with a step-by-step video.\nIn K-9 Mail 6.200 release, it supports for using OAuth 2.0 with Google, Yahoo, AOL, and personal Microsoft accounts (Office365 accounts are not supported yet). You don't need to input your Google password anymore, you just need to grant privilege to K-9 mail.\n","link":"https://dennys.github.io/en/posts/202207/k-9-mail-supports-oauth-2.0-gmail/","section":"posts","tags":["Software"],"title":"K-9 Mail 6.200 Supports OAuth 2.0 (gmail)"},{"body":"","link":"https://dennys.github.io/en/posts/","section":"posts","tags":null,"title":"Posts"},{"body":"Requirement Most cameras' filenames are like 'DC*****' or 'P*****', I want to find a tool that has the following features.\nBatch change filenames to P[photo capture date]-[camera model].jpg. For example, P20220710-101405-iPhone 13.jpg. Can change the camera model string, for example, I want to change \u0026quot;iPhone 6\u0026quot; to \u0026quot;i6\u0026quot;, \u0026quot;DMC-G6\u0026quot; to \u0026quot;G6\u0026quot;, \u0026quot;DSC-RX100M5A\u0026quot; to \u0026quot;R1005A\u0026quot;, ... Can add a serial number automatically when the new filename is duplicated with others. Software There are lots of rename tools. I try 3 tools, and all of them are freeware. (Rename Master is not open source, but it's not a problem.). F2 (by Go and ExifTool (by Perl) are cross-platform. Rename Master is for Windows only.\nF2 (GitHub: 480 stars) ExifTool (GitHub: 1.5K stars) Rename Master F2 First run, use its build-in function, the problem is it cannot get the capture date.\n1C:\\\u0026gt;f2 -r \u0026#39;P{{mtime.YYYY}}{{mtime.MM}}{{mtime.DD}}-{{mtime.H}}{{mtime.mm}}{{mtime.ss}}-{{x.model}}\u0026#39; 2┌─────────────────────────────────────────────────┐ 3| ORIGINAL | RENAMED | STATUS | 4| *********************************************** | 5| P1790419.JPG | P20220528-154122-DMC-G6 | ok | 6| P1790420.JPG | P20220528-154134-DMC-G6 | ok | 7| P1790421.JPG | P20220528-154140-DMC-G6 | ok | 8└─────────────────────────────────────────────────┘ 9INFO Use the -x or --exec flag to apply the above changes Second run, use ExitTool to get the capture date. Because the date format of DateTimeOriginal is something like 2003:10:31 15:44:19, it contains several commons and it's an invalid character in Windows file system.\n1C:\\\u0026gt;f2 -r \u0026#39;P{{xt.DateTimeOriginal}}-{{x.model}}\u0026#39; 2┌──────────────────────────────────────────────────────────────────────────────────────┐ 3| ORIGINAL | RENAMED | STATUS | 4| ************************************************************************************ | 5| P1790419.JPG | \u0026#39;P2022:06:25 10:47:16-DMC-G6\u0026#39; | invalid characters present: (:,:,:,:) | 6| P1790419.JPG | \u0026#39;P2022:06:25 10:47:21-DMC-G6\u0026#39; | invalid characters present: (:,:,:,:) | 7| P1790419.JPG | \u0026#39;P2022:06:25 10:47:27-DMC-G6\u0026#39; | invalid characters present: (:,:,:,:) | 8└──────────────────────────────────────────────────────────────────────────────────────┘ 9ERROR Resolve conflicts before proceeding or use the -F flag to auto fix all conflicts Third run, in ExifTool, you can change the format of DateTimeOriginal, it seems we cannot do it in F2. Therefore, please add a -F parameter, it will try to fix invalid characters. In this case, it removes all invalid characters.\n1C:\\\u0026gt;f2 -r \u0026#39;P{{xt.DateTimeOriginal}}-{{x.model}}\u0026#39; -F 2┌───────────────────────────────────────────────────┐ 3| ORIGINAL | RENAMED | STATUS | 4| ************************************************* | 5| P1790419.JPG | \u0026#39;P20220528 154122-DMC-G6\u0026#39; | ok | 6| P1790420.JPG | \u0026#39;P20220528 154135-DMC-G6\u0026#39; | ok | 7| P1790421.JPG | \u0026#39;P20220528 154140-DMC-G6\u0026#39; | ok | 8└───────────────────────────────────────────────────┘ 9INFO Use the -x or --exec flag to apply the above changes I stop my test here... Because although F2 is very fast, but F2+ExifTool is much slower than F2 only, I guess it's due to F2 calls ExifTool externally. I try to create a feature request to add the support for DateTimeOriginal, I hope the project owner will accept it: https://github.com/ayoisaiah/f2/issues/23\nExifTool First run, use Exif tool to rename files, because the Exif function is build-in, the peformance is faster than F2+ExifTool. 1C:\\\u0026gt;exiftool \u0026#34;-filename\u0026lt;${CreateDate}-${Exif:Model}.${filetype}\u0026#34; -d P%Y%m%d-%H%M%S%%-c * 2 3C:\\\u0026gt;dir 42022/05/28 下午 03:41 8,024,576 P20220528-154122-DMC-G6.JPEG 52022/05/28 下午 03:41 6,673,920 P20220528-154135-DMC-G6.JPEG 62022/05/28 下午 03:41 7,978,496 P20220528-154140-DMC-G6.JPEG I cannot find a parameter to show the result, I need to run dir to check the new filenames. If you know how to do it, please let me know, thanks. I cannot find a function to modify the camera model string in ExifTool, but it's possible to do it by F2 easily. But for my requirement, I need to run F2 many times like the following. It should be ok but I prefer to find a better solution. Run ExifTool to rename files Run F2 to rename files for my 1st camera/phone. Run F2 to rename files for my 2nd camera/phone. Run F2 to rename files for my 3rd camera/phone. ... Rename Master Finally, I try to use Rename Master, it's a Windows GUI application, you can add actions (add string, find and replace, add serial number, ...). This is my script, it has 5 steps:\nRemove all filename. Add filename with a 'P' character and date+time. Add camera model into the filename. Change the name of camera model (ex: \u0026quot;DSC-RX100M2\u0026quot; -\u0026gt; \u0026quot;S2\u0026quot;, \u0026quot;iPhone 6 Plus\u0026quot; to \u0026quot;i6\u0026quot;) If the filenames are duplicated, add serian number in last. If you have hundreds of files, it will hang for several seconds (depending on your files) to scan the file, please be patient!\nThe following is my script, if you like, you can download it into a xxx.rmscr and use Rename Master to open it. Then you can modify the script for your requirement.\n1[SCRIPT0] 2TYPE_unicode=7 3ENABLED_unicode=1 4cbAndStore_unicode=0 5cbRCReplace_unicode=0 6cbxRemoveCharactersPart_unicode=0 7cbxRemoveCharPosition_unicode=0 8txtR2X_unicode=50 9txtRCReplace_unicode= 10 11[SCRIPT1] 12TYPE_unicode=0 13ENABLED_unicode=1 14cbOnCollision_unicode=0 15cbxAddAtThe_unicode=0 16cbxAddPart_unicode=0 17txtAdd_unicode=P?x_dtd:FYYYYMMDD?-?x_dtd:FHHMMSS?- 18 19[SCRIPT2] 20TYPE_unicode=0 21ENABLED_unicode=1 22cbOnCollision_unicode=0 23cbxAddAtThe_unicode=1 24cbxAddPart_unicode=0 25txtAdd_unicode=?x_mo? 26 27[SCRIPT3] 28TYPE_unicode=3 29ENABLED_unicode=1 30cbReplaceOnly_unicode=0 31cbxReplacePart_unicode=2 32cbxReplaceTarget_unicode=0 33txtReplacePhrase_unicode=DSC-RX100M5A 34txtReplaceWith_unicode=S5A 35txtRP2X_unicode=1 36txtRP2Y_unicode=10 37 38[SCRIPT7] 39TYPE_unicode=3 40ENABLED_unicode=1 41cbReplaceOnly_unicode=0 42cbxReplacePart_unicode=2 43cbxReplaceTarget_unicode=0 44txtReplacePhrase_unicode=iPhone 6 Plus 45txtReplaceWith_unicode=i6 46txtRP2X_unicode=1 47txtRP2Y_unicode=10 48 49[SCRIPT12] 50TYPE_unicode=0 51ENABLED_unicode=1 52cbOnCollision_unicode=1 53cbxAddAtThe_unicode=1 54cbxAddPart_unicode=0 55txtAdd_unicode=-?n02? 56 57[Path] 58cbPath_unicode= 59 60[Filter] 61txtFilter_unicode=*.jpg 62 63[ScriptOptions] 64UseFilter_unicode=1 65UsePath_unicode=0 66 67[Version] 68Current_unicode=3.9 69 70[Counting] 71rbUsePositionInList_unicode=1 72rbStartCountingAt_unicode=0 73txtStartCountingAt_unicode=1 74txtIncrementBy_unicode=1 75 76[Case] 77cbOverrideCase_unicode=0 78rbCUppercase_unicode=1 79rbCLowercase_unicode=0 80rbCCapitalizeWords_unicode=0 81rbCCapitalizeSentence_unicode=0 82cbCPreserverExtension_unicode=0 83rbCTitleCase_unicode=0 84cbCRoman_unicode=0 85cbSplit_unicode=0 86txtSplit_unicode= 87 88[Wildcards] 89rbWildcards_unicode=1 90rbRegExp_unicode=0 91 92[Text] 93txtTName_unicode= 94udTSkip_unicode=0 95cbTDelim_unicode=1 96rbTMatch_unicode=1 97rbTFind_unicode=0 98txtTFind_unicode=?cfn? 99txtTDelim_unicode=, 100cbxSearchWith_unicode=0 Conclusion Other sofotwares There are lots of rename tools, you can try them...\nBulk Rename Utility: it seems this utility has lots of features and it supports writing javascript to rename files. But it's for personal use only, if you want to use it in commercial, you need to pay. Ant Renamer: The last change is 2015/04/07. Ken Rename: I cannot find its official website of it. ","link":"https://dennys.github.io/en/doc/software/batch-photo-files-rename-tools/","section":"doc","tags":["Software"],"title":"Batch Photo Files Rename Tools (by EXIF)."},{"body":"I usually use Spotify to listen to podcasts, but because I use Spotify with my children, I want to find another Podcast App for my personal use.\nAnd I find Pocket Casts has an interesting feature, it can skip the first or last *** seconds. It means some podcasts have an introduction at the beginning, if you want to skip it, you can do it in this app. (This feature is provided in the free version.)\nSteps:\nChoose your podcast. Click the gear icon. Input the length you want to skip in the first or last. ","link":"https://dennys.github.io/en/doc/software/how-to-skip-podcast-intro/","section":"doc","tags":["Software","Podcast"],"title":"How to Skip Podcast's Introduction"},{"body":"","link":"https://dennys.github.io/en/tags/podcast/","section":"tags","tags":null,"title":"Podcast"},{"body":"","link":"https://dennys.github.io/en/tags/database/","section":"tags","tags":null,"title":"Database"},{"body":"If you want to get the 1st record of range records, you can use this SQL command.\n1SELECT * FROM 2(SELECT DISTINCT rank() over(PARTITION BY a.username ORDER BY a.update_dt desc) rn, a.* 3 FROM table_name a 4 WHERE a.update_dt \u0026gt; p_cur_timestamp 5 AND a.update_dt \u0026lt;= p_cur_timestamp + C_PERIOD 6 ) 7WHERE rn = 1 ","link":"https://dennys.github.io/en/doc/database/get-first-record-of-a-range-sql/","section":"doc","tags":["Database"],"title":"SQL to get 1st record of a range"},{"body":"This site uses Utterances to manage comments. If you want to contact me, you can leave a message here. Because Utterances is based on GitHub, you need to login GitHub, thanks.\n","link":"https://dennys.github.io/en/comments/","section":"","tags":null,"title":"Comments"},{"body":"Family 👀\n👨👩 👧👧👧 Job 👨‍💻\nLike 🐶 🐱\nHave 🐰 🐇\n","link":"https://dennys.github.io/en/about/","section":"","tags":null,"title":"About"},{"body":"\rRemind\rThis is for .NET 4.8 or below only!!\rPrecondition You already have a GitLab (GitLab Saas or GitLab self-managed). This document is for .NET 4.X, if you want to build .NET core or .NET 5/6/7/..., you can use docker to run GitLab Runner.\nProcedure Step 1 - Prepare .NET build environment First, you need to prepare an environment to build .NET application. The easiest solution is to install Visual Studio. (Please let me know if I can build a .NET build environment without Visual Studio, thanks.) But it's strange, MSBuild.exe is not included in PATH after the installation. Please put C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\MSBuild\\Current\\Bin into your PATH. Step 2 - Install Git client Download and install Git for Windows. The portable version is ok, but because Git Runner is a Windows service, please add git.exe into PATH.\nStep 3 - Install GitLab Runner Download GitLab Runner for Windows.\nRename gitlab-runner-windows-amd64.exe to gitlab-runner.exe.\nGet the token to run GitLab Runner.\nGenerate GitLab Runner configuration file (config.toml) and run the command to register.\n1gitlab-runner.exe register --url https://gitlab.com/ --registration-token $REGISTRATION_TOKEN Modify config.toml\nBecause Gitlab Runner doesn't support Windows shell after version 13, you need to use PowerShell, you have 2 options: If you use Power Shell, please open config.toml and rename 'pwsh' to 'powershell'. If you use Power Shell Core, you don't need to do anything. If you find your log is garbled (ex: your Windows server is not an English version), please add chcp 65001 to change the encoding to UTF-8. If you use a portable Git, you need to modify $env:Path in config.toml. (comment line 13 and uncomment line 14) 1listen_address = \u0026#34;[::]:9252\u0026#34; 2concurrent = 4 3check_interval = 0 4 5[session_server] 6 session_timeout = 1800 7[[runners]] 8 name = \u0026#34;Windows Runner 01 (not docker)\u0026#34; 9 url = \u0026#34;https://gitlab.com/\u0026#34; 10 token = \u0026#34;******************\u0026#34; 11 executor = \u0026#34;shell\u0026#34; 12 shell = \u0026#34;powershell\u0026#34; 13 pre_clone_script = \u0026#34; chcp 65001\\n $OutputEncoding = [console]::InputEncoding = [console]::OutputEncoding = New-Object System.Text.UTF8Encoding\\n \u0026#34; 14 # pre_clone_script = \u0026#34; chcp 65001\\n $env:Path = \\\u0026#34;C:\\\\Gitlab\\\\PortableGit\\\\cmd;$env:Path\\\u0026#34;\\n\\t $OutputEncoding = [console]::InputEncoding = [console]::OutputEncoding = New-Object System.Text.UTF8Encoding\\n \u0026#34; 15 pre_build_script = \u0026#34; chcp 65001\\n \u0026#34; 16 [runners.custom_build_dir] 17 [runners.cache] 18 [runners.cache.s3] 19 [runners.cache.gcs] 20 [runners.cache.azure] Register GitLab Runner as a Windows service and start it.\nRun the command gitlab-runner install to install as a Windows service. Run the command gitlab-runner start to start the service. remember, if you modify the file, please execute gitlab-runner.exe restart to restart GitLab runner.\nIf you always see the Credential Helper Selector, please choose \u0026quot;no helper\u0026quot; and \u0026quot;Always use this from now on\u0026quot;.\nStep 4 - Write .gitlab-ci.yml Edit .gitlab-ci.yml, the following is a sample: 1stages: 2 - build 3 - test 4build: 5 stage: build 6 script: 7 - \u0026#34;dotnet build\u0026#34; 8 artifacts: 9 paths: 10 - .\\test 11test: 12 stage: test 13 script: 14 - \u0026#34;dotnet test\u0026#34; Step 5 - Start to build/test/deploy code (on local machine) Before you start to run CI/CD on your GitLab, you can try it on your local machine. It's easier to debug in a local environment. Please change the directory to the location of .gitlab-ci.yml and execute this command. 1C:\\Gitlab\\builds\\j5AFD9Qz\\0\\gis\\commission_moi_dtm\u0026gt; gitlab-runner.exe exec shell build 2Runtime platform arch=amd64 os=windows pid=13728 revision=e91107dd version=14.5.2 3Running with gitlab-runner 14.5.2 (e91107dd) 4Preparing the \u0026#34;shell\u0026#34; executor 5Using Shell executor... 6executor not supported job=1 project=0 referee=metrics 7Preparing environment 8Running on GITRUNNER01... 9DEPRECATION: CMD shell is deprecated and will no longer be supported 10Getting source from Git repository 11Fetching changes... 12Initialized empty Git repository in C:/Gitlab/builds/j5AFD9Qz/0/gis/**********/builds/0/project-0/.git/ 13Created fresh repository. 14Checking out 1ff057d4 as HEAD... 15... Step 6 - Start to test CI/CD (on GitLab) If everything is ok, you can commit .gitlab-ci.yml and GitLab should run it automatically.\nSAST (Static Application Security Testing) GitLab can check your source code for known vulnerabilities, unfortunately, it only supports Linux containers, and Windows containers are not yet supported. (reference: https://docs.gitlab.com/ee/user/application_security/sast/)\n","link":"https://dennys.github.io/en/doc/devops/gitlab-dotnet4-ci-cd/","section":"doc","tags":["GitLab",".NET","CI/CD"],"title":"Use GitLab to do .NET 4.8 CI/CD"},{"body":"","link":"https://dennys.github.io/en/tags/ifttt/","section":"tags","tags":null,"title":"IFTTT"},{"body":"Requirement I want to have daily mail including currency exchange rate information.\nMail subject: include the exchange rate in the mail subject. Mail content: Has some links to banks' exchange rate pages. Include some exchange rate history charts. Solution Use ifttt.com\nCreate a new Applet on IFTTT\nAdd a new \u0026quot;If This\u0026quot;\nChoose \u0026quot;finance\u0026quot; service\nChoose \u0026quot;Today's exchange rate report\u0026quot;\nChoose the input/output currency and trigger time.\nAdd a new \u0026quot;Then That\u0026quot;\nChoose a \u0026quot;gmail\u0026quot; service\nIf you just want to send yourself an email, you can click the right button. If you want to send to several recipients, you can click left button.\nThis is an example to send yourself an email.\nThis is my email body\n1As of {{CheckTime}}, 1 {{InputCurrency}} equals {{ExchangeRate}} {{OutputCurrency}}.\u0026lt;br\u0026gt; 2\u0026lt;br\u0026gt; 3via {{InfoUrl}} 4 5\u0026lt;b\u0026gt;美元匯率:\u0026lt;/b\u0026gt; 6\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt; 7\u0026lt;a href=\u0026#34;https://rate.bot.com.tw/xrt?Lang=zh-TW\u0026#34;\u0026gt;即時\u0026lt;/a\u0026gt;(台銀)\u0026amp;nbsp; 8\u0026lt;a href=\u0026#34;https://rate.bot.com.tw/xrt/quote/day/USD\u0026#34;\u0026gt;當日\u0026lt;/a\u0026gt;(台銀)\u0026amp;nbsp; 9\u0026lt;a href=\u0026#34;https://www.xe.com/currencycharts/?from=USD\u0026amp;to=TWD\u0026amp;view=1W\u0026#34;\u0026gt;1周\u0026lt;/a\u0026gt;(XE)\u0026amp;nbsp; 10\u0026lt;a href=\u0026#34;https://www.xe.com/currencycharts/?from=USD\u0026amp;to=TWD\u0026amp;view=1M\u0026#34;\u0026gt;1個月\u0026lt;/a\u0026gt;(XE)\u0026amp;nbsp; 11\u0026lt;a href=\u0026#34;https://rate.bot.com.tw/xrt/quote/ltm/USD\u0026#34;\u0026gt;3個月\u0026lt;/a\u0026gt;(台銀)\u0026amp;nbsp; 12\u0026lt;a href=\u0026#34;https://rate.bot.com.tw/xrt/quote/l6m/USD\u0026#34;\u0026gt;6個月\u0026lt;/a\u0026gt;(台銀) 13\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt; 14\u0026lt;a href=\u0026#34;https://rate.bot.com.tw/xrt/quote/l1y/USD\u0026#34;\u0026gt;1年\u0026lt;/a\u0026gt;(台銀)\u0026amp;nbsp; 15\u0026lt;a href=\u0026#34;https://www.esunbank.com.tw/bank/personal/deposit/rate/forex/exchange-rate-chart?Currency=USD/TWD\u0026#34;\u0026gt;1年\u0026lt;/a\u0026gt;(玉山)\u0026amp;nbsp; 16\u0026lt;a href=\u0026#34;https://www.xe.com/currencycharts/?from=USD\u0026amp;to=TWD\u0026amp;view=1Y\u0026#34;\u0026gt;1年\u0026lt;/a\u0026gt;(XE)\u0026amp;nbsp; 17\u0026lt;a href=\u0026#34;https://rate.bot.com.tw/xrt/quote/l3y/USD\u0026#34;\u0026gt;3年\u0026lt;/a\u0026gt;(台銀)\u0026amp;nbsp; 18\u0026lt;a href=\u0026#34;https://www.xe.com/currencycharts/?from=USD\u0026amp;to=TWD\u0026amp;view=5Y\u0026#34;\u0026gt;5年\u0026lt;/a\u0026gt;(XE)\u0026amp;nbsp; 19\u0026lt;a href=\u0026#34;https://www.xe.com/currencycharts/?from=USD\u0026amp;to=TWD\u0026amp;view=10Y\u0026#34;\u0026gt;10年\u0026lt;/a\u0026gt;(XE)\u0026amp;nbsp; 20\u0026lt;a href=\u0026#34;https://fxtop.com/en/historical-exchange-rates.php?A=1\u0026amp;C1=USD\u0026amp;C2=TWD\u0026amp;DD1=\u0026amp;MM1=\u0026amp;YYYY1=\u0026amp;B=1\u0026amp;P=\u0026amp;I=1\u0026amp;DD2=03\u0026amp;MM2=03\u0026amp;YYYY2=2099\u0026amp;btnOK=Go%21\u0026#34;\u0026gt;1983~現在\u0026lt;/a\u0026gt;(FXTOP)\u0026amp;nbsp; 21\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt; 22\u0026lt;a href=\u0026#34;https://historical.findrate.tw/USD/\u0026#34;\u0026gt;1個月+1年+10年\u0026lt;/a\u0026gt;(FindRate) 23\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;br/\u0026gt; 24 25\u0026lt;b\u0026gt;2022/1/1~2022/12/31:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt; 26\u0026lt;img src=\u0026#34;https://fxtop.com/php/imggraph.php?C1=USD\u0026amp;C2=TWD\u0026amp;A=1\u0026amp;DD1=\u0026amp;MM1=01\u0026amp;YYYY1=2022\u0026amp;DD2=\u0026amp;MM2=12\u0026amp;YYYY2=2022\u0026amp;LANG=en\u0026amp;CJ=0\u0026amp;MM1Y=1\u0026amp;LARGE=\u0026amp;TR=OFF\u0026#34;\u0026gt;\u0026lt;br/\u0026gt; 27\u0026lt;b\u0026gt;2021/1/1~2022/12/31:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt; 28\u0026lt;img src=\u0026#34;https://fxtop.com/php/imggraph.php?C1=USD\u0026amp;C2=TWD\u0026amp;A=1\u0026amp;DD1=\u0026amp;MM1=01\u0026amp;YYYY1=2021\u0026amp;DD2=\u0026amp;MM2=12\u0026amp;YYYY2=2022\u0026amp;LANG=en\u0026amp;CJ=0\u0026amp;MM1Y=1\u0026amp;LARGE=\u0026amp;TR=OFF\u0026#34;\u0026gt;\u0026lt;br/\u0026gt; 29\u0026lt;b\u0026gt;2020/1/1~2022/12/31:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt; 30\u0026lt;img src=\u0026#34;https://fxtop.com/php/imggraph.php?C1=USD\u0026amp;C2=TWD\u0026amp;A=1\u0026amp;DD1=\u0026amp;MM1=01\u0026amp;YYYY1=2020\u0026amp;DD2=\u0026amp;MM2=12\u0026amp;YYYY2=2022\u0026amp;LANG=en\u0026amp;CJ=0\u0026amp;MM1Y=1\u0026amp;LARGE=\u0026amp;TR=OFF\u0026#34;\u0026gt;\u0026lt;br/\u0026gt; 31\u0026lt;b\u0026gt;2000/1/1~2022/12/31:\u0026lt;/b\u0026gt;\u0026lt;br/\u0026gt; 32\u0026lt;img src=\u0026#34;https://fxtop.com/php/imggraph.php?C1=USD\u0026amp;C2=TWD\u0026amp;A=1\u0026amp;DD1=\u0026amp;MM1=01\u0026amp;YYYY1=2000\u0026amp;DD2=\u0026amp;MM2=12\u0026amp;YYYY2=2022\u0026amp;LANG=en\u0026amp;CJ=0\u0026amp;MM1Y=1\u0026amp;LARGE=\u0026amp;TR=OFF\u0026#34;\u0026gt;\u0026lt;br/ Mail sample IFTTT applet location This is my IFTTT applet: https://ifttt.com/applets/SxPJ2fpv-\nAbout the exchange rate history chart I only find 2 websites that provide exchange rate charts to embed in the mail content.\nhttps://fxtop.com/, it provides PNG format chart, I already include it in my IFTTT applet. https://www.currencyconverterrate.com/, it provides SVG format chart (ex: https://www.currencyconverterrate.com/currencycharts/usd/usd-twd-exchange-rates-history-chart-7-day.svg), but I cannot find a solution to show SVG in gmail. If you find a solution, please let me know, thanks. ","link":"https://dennys.github.io/en/doc/ifttt/ifttt-send-currency-exchange-rate-mail/","section":"doc","tags":["IFTTT"],"title":"Use IFTTT to send currency exchange rate mail daily"},{"body":"Requirement I want to have daily mail including currency exchange rate information.\nSolution use https://wise.com (no need to register an account)\nConnect to https://wise.com/tools/exchange-rate-alerts/ Input the currency exchange rate you want to know and your email address. Mail result You will receive the mail daily.\n","link":"https://dennys.github.io/en/doc/software/wise-send-currency-exchange-rate-mail/","section":"doc","tags":["Software"],"title":"Use WISE to send currency exchange rate mail daily"},{"body":"","link":"https://dennys.github.io/en/tags/checkmarx/","section":"tags","tags":null,"title":"Checkmarx"},{"body":"\rPurpose Checkmarx is a good tool to do code analysis, but there are 2 pain points during the flow.\nCheckmarx can integrate SCM like GitHub/GitLab/..., but it cannot be triggered by by a code commit, it can only schedule the job to run the scan. (If I don't commit code, I don't want to waste resources scanning the code.) Checkmarx has a built-in issue tracking system, but I think most people prefer to use their issue tracking system in their Git or JIRA or ... What we want is to integrate Checkmarx scan into GitLab's CI/CD flow including\nWhen we commit code to GitLab, it will trigger Checkmarx to scan automatically. After the scan, Checkmarx will create issues in GitLab. Procedure GitLab admin configuration You need to set some global variables in GitLab CI/CD admin (Menu-\u0026gt;Admin-\u0026gt;Settings-\u0026gt;CI/CD-\u0026gt;Variables). You need to set CHECKMARX_XXX and CX_TEAM variables to integrate Checkmarx. And if you want Checkmarx to create GitLab issue, please also set GITLAB_URL and GITLAB_TOKEN. (You can reference here for the detail) GitLab project configuration It's very easy to enable Checkmarx analysis in your GitLab jobs, you just need to edit your .gitlab-ci.yml and include Checkmarx's yml into it (line 1). And you also need to assign Checkmarx's project name in this yml file (line 4).\n1include: \u0026#39;https://raw.githubusercontent.com/checkmarx-ltd/cx-flow/develop/templates/gitlab/v3/Checkmarx.gitlab-ci.yml\u0026#39; 2 3variables: 4 CX_PROJECT: ProjectXXX #The project name you want to show in Checkmarx Then you can try to commit code to trigger a CI/CD flow, Checkmarx analysis will be triggered in 2 conditions:\nWhen you create a merge request in GitLab. When you commit code to master stream directly. The following is a log sample, please check line 20, you can see the variables you defined in GitLab.\n1Running with gitlab-runner 14.5.2 (e91107dd) 2 on Runner in PC vYY9jCrR 3Preparing the \u0026#34;docker\u0026#34; executor 400:06 5Using Docker executor with image checkmarx/cx-flow ... 6Pulling docker image checkmarx/cx-flow ... 7Using docker image sha256:22f48d49aa64275d09b1650c359c0a9b1ab9fa771efa01fba4af89f511b93481 for checkmarx/cx-flow with digest checkmarx/cx-flow@sha256:2b2a2f09680e6c3ba21b00cf8ab4005baa133f0eeeaeb406f09b01a832fffb67 ... 8Preparing environment 900:01 10Running on runner-vyy9jcrr-project-33-concurrent-0 via 435566b8ed7c... 11Getting source from Git repository 1200:14 13Fetching changes... 14 15...... 16 17 18Executing \u0026#34;step_script\u0026#34; stage of the job script 19Using docker image sha256:22f48d49aa64275d09b1650c359c0a9b1ab9fa771efa01fba4af89f511b93481 for checkmarx/cx-flow with digest checkmarx/cx-flow@sha256:2b2a2f09680e6c3ba21b00cf8ab4005baa133f0eeeaeb406f09b01a832fffb67 ... 20$ ${CX_FLOW_EXE} --scan --app=\u0026#34;${CI_PROJECT_NAME}\u0026#34; --namespace=\u0026#34;${CI_PROJECT_NAMESPACE}\u0026#34; --repo-name=\u0026#34;${CI_PROJECT_NAME}\u0026#34; --repo-url=\u0026#34;${CI_REPOSITORY_URL}\u0026#34; --cx-team=\u0026#34;${CX_TEAM}\u0026#34; --cx-project=\u0026#34;${CX_PROJECT}\u0026#34; --branch=\u0026#34;${CI_COMMIT_BRANCH}\u0026#34; --spring.profiles.active=\u0026#34;${CX_FLOW_ENABLED_VULNERABILITY_SCANNERS}\u0026#34; --f=. ${PARAMS} 21SLF4J: Class path contains multiple SLF4J bindings. 22SLF4J: Found binding in [jar:file:/app/cx-flow.jar!/BOOT-INF/lib/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class] 23SLF4J: Found binding in [jar:file:/app/cx-flow.jar!/BOOT-INF/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class] 24SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. 25SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder] 26 ___ ___ _ 27 / __\\_ __ / __\\ | _____ __ 28 / / \\ \\/ /____ / _\\ | |/ _ \\ \\ /\\ / / 29/ /___ \u0026gt; \u0026lt;_____/ / | | (_) \\ V V / 30\\____//_/\\_\\ \\/ |_|\\___/ \\_/\\_/ 312022-01-21 06:44:09.841 WARN 11 --- [ main] o.s.b.StartupInfoLogger [] : InetAddress.getLocalHost().getHostName() took 5006 milliseconds to respond. Please verify your network configuration. 322022-01-21 06:44:14.858 INFO 11 --- [ main] c.c.f.CxFlowApplication [] : Starting CxFlowApplication with PID 11 (/app/cx-flow.jar started by root in /builds/*********) 332022-01-21 06:44:14.858 INFO 11 --- [ main] c.c.f.CxFlowApplication [] : The following profiles are active: sast 342022-01-21 06:44:18.305 INFO 11 --- [ main] ptablePropertiesBeanFactoryPostProcessor [] : Post-processing PropertySource instances 352022-01-21 06:44:18.464 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource configurationProperties [org.springframework.boot.context.properties.source.ConfigurationPropertySourcesPropertySource] to AOP Proxy 362022-01-21 06:44:18.467 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource commandLineArgs [org.springframework.core.env.SimpleCommandLinePropertySource] to EncryptableEnumerablePropertySourceWrapper 372022-01-21 06:44:18.467 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource systemProperties [org.springframework.core.env.PropertiesPropertySource] to EncryptableMapPropertySourceWrapper 382022-01-21 06:44:18.468 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource systemEnvironment [org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor$OriginAwareSystemEnvironmentPropertySource] to EncryptableSystemEnvironmentPropertySourceWrapper 392022-01-21 06:44:18.468 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource random [org.springframework.boot.env.RandomValuePropertySource] to EncryptablePropertySourceWrapper 402022-01-21 06:44:18.469 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource applicationConfig: [classpath:/application-sast.yml] [org.springframework.boot.env.OriginTrackedMapPropertySource] to EncryptableMapPropertySourceWrapper 412022-01-21 06:44:18.469 INFO 11 --- [ main] c.u.j.EncryptablePropertySourceConverter [] : Converting PropertySource applicationConfig: [classpath:/application.yml] [org.springframework.boot.env.OriginTrackedMapPropertySource] to EncryptableMapPropertySourceWrapper 422022-01-21 06:44:18.607 INFO 11 --- [ main] c.u.j.f.DefaultLazyPropertyFilter [] : Property Filter custom Bean not found with name \u0026#39;encryptablePropertyFilter\u0026#39;. Initializing Default Property Filter 432022-01-21 06:44:18.620 INFO 11 --- [ main] c.u.j.r.DefaultLazyPropertyResolver [] : Property Resolver custom Bean not found with name \u0026#39;encryptablePropertyResolver\u0026#39;. Initializing Default Property Resolver 442022-01-21 06:44:18.629 INFO 11 --- [ main] c.u.j.d.DefaultLazyPropertyDetector [] : Property Detector custom Bean not found with name \u0026#39;encryptablePropertyDetector\u0026#39;. Initializing Default Property Detector 452022-01-21 06:44:18.934 WARN 11 --- [ main] j.p.spi [] : javax.persistence.spi::No valid providers found. 462022-01-21 06:44:18.938 INFO 11 --- [ main] trationDelegate$BeanPostProcessorChecker [] : Bean \u0026#39;org.hibernate.validator.internal.constraintvalidators.bv.NotBlankValidator\u0026#39; of type [org.hibernate.validator.internal.constraintvalidators.bv.NotBlankValidator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 472022-01-21 06:44:18.942 INFO 11 --- [ main] trationDelegate$BeanPostProcessorChecker [] : Bean \u0026#39;org.hibernate.validator.internal.constraintvalidators.bv.NotNullValidator\u0026#39; of type [org.hibernate.validator.internal.constraintvalidators.bv.NotNullValidator] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 482022-01-21 06:44:18.944 INFO 11 --- [ main] trationDelegate$BeanPostProcessorChecker [] : Bean \u0026#39;flowProperties\u0026#39; of type [com.checkmarx.flow.config.FlowProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 492022-01-21 06:44:18.947 INFO 11 --- [ main] trationDelegate$BeanPostProcessorChecker [] : Bean \u0026#39;flowAsyncConfig\u0026#39; of type [com.checkmarx.flow.config.FlowAsyncConfig$$EnhancerBySpringCGLIB$$9e6d5344] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) 502022-01-21 06:44:22.959 INFO 11 --- [ main] o.s.w.s.s.SaajSoapMessageFactory [] : Creating SAAJ 1.3 MessageFactory with SOAP 1.1 Protocol 512022-01-21 06:44:23.569 INFO 11 --- [ main] o.s.s.c.ThreadPoolTaskExecutor [] : Initializing ExecutorService 522022-01-21 06:44:23.571 INFO 11 --- [ main] o.s.s.c.ThreadPoolTaskExecutor [] : Initializing ExecutorService \u0026#39;scanRequest\u0026#39; 532022-01-21 06:44:23.576 INFO 11 --- [ main] o.s.s.c.ThreadPoolTaskExecutor [] : Initializing ExecutorService 542022-01-21 06:44:23.577 INFO 11 --- [ main] o.s.s.c.ThreadPoolTaskExecutor [] : Initializing ExecutorService \u0026#39;webHook\u0026#39; 552022-01-21 06:44:23.790 INFO 11 --- [ main] c.c.f.CxFlowRunner [] : =======BUILD INFO======= 562022-01-21 06:44:23.791 INFO 11 --- [ main] c.c.f.CxFlowRunner [] : Version: cx-flow-1.6.29 572022-01-21 06:44:23.792 INFO 11 --- [ main] c.c.f.CxFlowRunner [] : Time: 2022-01-07T12:45:49.239Z 582022-01-21 06:44:23.793 INFO 11 --- [ main] c.c.f.CxFlowRunner [] : ======================= 592022-01-21 06:44:25.426 INFO 11 --- [ main] c.c.f.CxFlowApplication [] : Started CxFlowApplication in 32.909 seconds (JVM running for 34.89) 602022-01-21 06:44:25.457 INFO 11 --- [ main] c.c.f.CxFlowRunner [blKXd4Ey] : Using custom bean implementation for bug tracking 612022-01-21 06:44:25.539 INFO 11 --- [ main] c.c.f.s.ScaFilterFactory [blKXd4Ey] : Initializing SCA filters. 622022-01-21 06:44:25.541 INFO 11 --- [ main] c.c.f.CxFlowRunner [blKXd4Ey] : Executing scan process 632022-01-21 06:44:25.551 INFO 11 --- [ main] c.c.f.s.ScaFilterFactory [blKXd4Ey] : Initializing SCA filters. 642022-01-21 06:44:25.571 INFO 11 --- [ main] c.c.f.s.ProjectNameGenerator [blKXd4Ey] : Project name being used: ********* 652022-01-21 06:44:25.573 INFO 11 --- [ main] c.c.f.u.ZipUtils [blKXd4Ey] : Creating zip file /builds/*********/cx.1357f707-5066-486c-b6f5-1d9dc08a4ad9.zip from contents of path . 662022-01-21 06:44:25.573 INFO 11 --- [ main] c.c.f.u.ZipUtils [blKXd4Ey] : Applying exclusions: .jar 672022-01-21 06:44:47.686 INFO 11 --- [ main] c.c.f.u.ZipUtils [blKXd4Ey] : Successfully created /builds/*********/cx.1357f707-5066-486c-b6f5-1d9dc08a4ad9.zip 682022-01-21 06:44:47.688 INFO 11 --- [ main] c.c.f.s.ScanRequestConverter [blKXd4Ey] : Overriding team with /CxServer/TEAM*** 692022-01-21 06:44:47.702 INFO 11 --- [ main] c.c.s.s.CxAuthService [blKXd4Ey] : Logging into Checkmarx https://***.com/cxrestapi/auth/identity/connect/token 702022-01-21 06:44:48.665 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Retrieving Cx teams 712022-01-21 06:44:48.700 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Found team /CxServer/TEAM*** with ID 16 722022-01-21 06:44:48.920 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Creating scan... 732022-01-21 06:44:48.921 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Updating Source details for project Id 67 742022-01-21 06:45:05.838 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Scan will be Full Scan 752022-01-21 06:45:05.840 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Creating Scan for project Id 67 762022-01-21 06:45:06.021 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Scan created with Id 1000207 for project Id 67 772022-01-21 06:45:06.171 INFO 11 --- [ main] jsonLogger [blKXd4Ey] : 782022-01-21 07:22:12.549 INFO 11 --- [ main] jsonLogger [blKXd4Ey] : 792022-01-21 07:22:12.551 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Creating report for xml Id 1000207 802022-01-21 07:22:12.906 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Report with Id 304 created 812022-01-21 07:22:17.908 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Retrieving report status of report Id 304 822022-01-21 07:22:18.965 INFO 11 --- [ main] c.c.s.s.CxAuthService [blKXd4Ey] : Logging into Checkmarx for SOAP token https://***.com/cxrestapi/auth/identity/connect/token 832022-01-21 07:22:19.117 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Retrieving report contents of report Id 304 in XML format 842022-01-21 07:22:19.220 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Report downloaded for report Id 304 852022-01-21 07:22:19.805 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Fetching Scan data for Id 1000207 862022-01-21 07:22:19.820 INFO 11 --- [ main] c.c.s.s.CxService [blKXd4Ey] : Fetching custom fields from project ID 67 872022-01-21 07:22:19.908 INFO 11 --- [ main] c.c.f.s.ResultsService [blKXd4Ey] : Issue tracking is custom bean implementation 882022-01-21 07:22:19.923 INFO 11 --- [ main] c.c.f.c.GitLabIssueTracker [blKXd4Ey] : Initializing GitLab processing 892022-01-21 07:22:20.325 INFO 11 --- [ main] c.c.f.s.CodeBashingService [blKXd4Ey] : not using CodeBashing lessons integration - one or more of the mandatory properties is missing 902022-01-21 07:22:20.325 INFO 11 --- [ main] c.c.f.s.IssueService [blKXd4Ey] : Processing Issues with custom bean GitLab 912022-01-21 07:22:20.325 INFO 11 --- [ main] c.c.f.c.GitLabIssueTracker [blKXd4Ey] : Executing getIssues GitLab API call 922022-01-21 07:22:20.465 INFO 11 --- [ main] c.c.f.s.IssueService [blKXd4Ey] : Issue still exists. Updating issue with key CX Second_Order_SQL_Injection @ ***.cs [master] 932022-01-21 07:22:21.352 INFO 11 --- [ main] c.c.f.c.GitLabIssueTracker [blKXd4Ey] : Finalizing GitLab Processing 942022-01-21 07:22:21.352 INFO 11 --- [ main] c.c.f.s.ResultsService [blKXd4Ey] : ####Checkmarx Scan Results Summary#### 952022-01-21 07:22:21.352 INFO 11 --- [ main] c.c.f.s.ResultsService [blKXd4Ey] : Team: /CxServer/TEAM***, Project: *********, Scan-Id: 1000207 962022-01-21 07:22:21.353 INFO 11 --- [ main] c.c.f.s.ResultsService [blKXd4Ey] : The vulnerabilities found for the scan are: high: 2, medium: 21, low: 156, info: 0 972022-01-21 07:22:21.353 INFO 11 --- [ main] c.c.f.s.ResultsService [blKXd4Ey] : To view results use following link: https://***.com/CxWebClient/ViewerMain.aspx?scanid=1000207\u0026amp;projectid=67 982022-01-21 07:22:21.353 INFO 11 --- [ main] c.c.f.s.ResultsService [blKXd4Ey] : ###################################### 992022-01-21 07:22:21.353 INFO 11 --- [ main] c.c.f.s.ThresholdValidatorImpl [blKXd4Ey] : Checking Thresholds exists. sast thresholds: false. sca thresholds: false 1002022-01-21 07:22:21.353 INFO 11 --- [ main] c.c.f.CxFlowRunner [blKXd4Ey] : Build succeeded. all checks passed 1012022-01-21 07:22:21.353 INFO 11 --- [ main] c.c.f.CxFlowRunner [blKXd4Ey] : Completed Successfully 1022022-01-21 07:22:21.354 INFO 11 --- [ main] c.c.f.CxFlowRunner [blKXd4Ey] : Finished with exit code: 0 1032022-01-21 07:22:21.359 INFO 11 --- [extShutdownHook] o.s.s.c.ThreadPoolTaskExecutor [] : Shutting down ExecutorService \u0026#39;webHook\u0026#39; 1042022-01-21 07:22:21.362 INFO 11 --- [extShutdownHook] o.s.s.c.ThreadPoolTaskExecutor [] : Shutting down ExecutorService \u0026#39;scanRequest\u0026#39; 105Cleaning up project directory and file based variables 10600:05 107Job succeeded During the Checkmarx analysis, you can check the status from its GUI, it takes a long time to analyze.\nAfter the analysis, you can check the result in Checkmarx or GitLab.\nCheck the result in Checkmarx.\nCheck the result in GitLab, it generates 1 report in merge request and it will create several issues by category. The following is the reqport of a merge request. In this report, there are 9 high issues (in 5 categories). The following are the 5 issues created by Checkmarx in GitLab. You can click above issue, it shows the detail vulnerability information. Troubleshooting If you find Checkmarx cannot find your team, please make sure to use English only in CX_TEAM, if you use non-English (ex: Chinese or Japanese), you can check the log and find it cannot find the team. 12022-01-12 02:51:22.748 INFO 11 --- [main] c.c.s.s.CxService [x4DNMhOL] : Found team /CxServer/Team1 with ID 16 Reference You can reference the official document to do the integration: https://checkmarx.atlassian.net/wiki/spaces/SD/pages/1929937052/GitLab+Integration. Conclusion After this integration, you just need to commit the code and see the result in GitLab. All flows are in GitLab now, you don't need to worry about Checkmarx. Checkmarx provides lots of integration, you can reference https://checkmarx.atlassian.net/wiki/spaces/SD/pages/1339162785/CxSAST+CxSCA+Plugins+and+Integrations. What's next Try to integrate the scan result to SonarQube), you can reference https://dennys.github.io/en/doc/devops/gitlab-checkmarx-sonarqube-integration/. ","link":"https://dennys.github.io/en/doc/devops/gitlab-checkmarx-integration/","section":"doc","tags":["GitLab","Checkmarx"],"title":"GitLab Checkmarx CI/CD Integration"},{"body":"\rPurpose In previous article, we know how to integrate GitLab and Checkmarx. In this article, we want to integrate SonarQube too. When we commit code to GitLab, we want GitLab to trigger these actions automatically:\nGitLab sends the code to Checkmarx to scan. GitLab triggers SonarQube to scan. SonarQube integrates Checkmarx's report. Procedure You can reference the official document: https://checkmarx.atlassian.net/wiki/spaces/SD/pages/169246832/SonarQube+Plugin+v8.5.0+and+up\nDownload the plugin from here, it only supports SonarQube LTS version (for now, it's 8.x) Configurea Quality Gate/Profiles of SonarQube for Checkmarx's rules. Use GitLab to trigger Checkmarx scan and record the project name of Checkmarx. Configure Checkmarx data in SonarQube, which you can reference here. Trigger GitLab CI again, you will see the following log in your SonarQube job 1INFO: Sensor Import Checkmarx scan results to SonarQube [checkmarx] 2INFO: Retrieving Checkmarx scan results for current module [Checkmarx plugin version: 2021.2.1] 3INFO: Getting Checkmarx configuration data from sonar Database. 4INFO: Resolving Cx setting: checkmarx.server.project_name 5INFO: Forced authentication is enabled: Sonar credentials must be provided 6INFO: Sonar server token is provided 7INFO: Checkmarx credentials migration not needed 8INFO: Sonar server token is provided 9INFO: Resolving Cx setting: checkmarx.server.project_name 10INFO: Forced authentication is enabled: Sonar credentials must be provided 11INFO: Checkmarx server version [9.2.0.41015]. Hotfix [24]. 12INFO: Logging into the Checkmarx service. 13INFO: Connecting to https://your.checkmarx.server/ 14INFO: Initializing Cx client [2020.2.4.NO.SCA] 15INFO: Checkmarx server version [9.2.0.41015]. Hotfix [24]. 16INFO: Logging into the Checkmarx service. 17INFO: full team path: \\CxServer\\\\Team1 18INFO: preset name: All 19INFO: ---------------------------------Get Last CxSAST Results:-------------------------------- 20INFO: Waiting for server to generate xml report. 4990 seconds left to timeout 21INFO: Checkmarx High vulnerabilities: 3 22INFO: Checkmarx New-High vulnerabilities: 0 23INFO: Checkmarx Medium vulnerabilities: 23 24INFO: Checkmarx New-Medium vulnerabilities: 1 25INFO: Checkmarx Low vulnerabilities: 142 26INFO: Checkmarx New-Low vulnerabilities: 7 27INFO: Checkmarx scan link: https://your.checkmarx.server//CxWebClient/ViewerMain.aspx?scanId=1000157\u0026amp;ProjectID=67 You can see the Checkmarx issues in SonarQube now. Problem I find some issues are not created in SonarQube and it seems due to the rule is not defined in Checkmarx's SonarQube plugin. I'm still checking it.\n","link":"https://dennys.github.io/en/doc/devops/gitlab-checkmarx-sonarqube-integration/","section":"doc","tags":["GitLab","Checkmarx","SonarQube"],"title":"GitLab Checkmarx SonarQube Integration"},{"body":"Check table size (remember to check last_analyzed_date) 1SELECT * FROM all_tables WHERE table_name LIKE \u0026#39;AB%\u0026#39; Re-analyze table 1ANALYZE table TABLE_NAME estimate statisitics Check index-related information (it doesn't contain block information) 1SELECT * FROM all_indexes WHERE table_name LIKE \u0026#39;AB%\u0026#39; Re-analyze index: 1ANALYZE index INDEX_NAME validate structure; Check index size: (it only checks the last analyzed index) 1SELECT * FROM index_stats; Others An index needs to be rebuilt, deleting or updating records will NOT free the index block Need DBA to check the block's definition. ","link":"https://dennys.github.io/en/doc/database/how-to-analyze-size-of-table-index/","section":"doc","tags":["Database"],"title":"How to analyze size of table, index in Oracle"},{"body":"","link":"https://dennys.github.io/en/tags/ci/cd/","section":"tags","tags":null,"title":"CI/CD"},{"body":"","link":"https://dennys.github.io/en/categories/ci/cd/","section":"categories","tags":null,"title":"CI/CD"}]